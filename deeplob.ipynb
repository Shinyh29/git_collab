{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nfrom keras import layers\nfrom keras.models import Model\nfrom keras import Input\nfrom keras.layers import LSTM\nfrom keras.utils import to_categorical\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-12T04:24:11.411887Z","iopub.execute_input":"2021-09-12T04:24:11.412185Z","iopub.status.idle":"2021-09-12T04:24:13.722396Z","shell.execute_reply.started":"2021-09-12T04:24:11.412140Z","shell.execute_reply":"2021-09-12T04:24:13.721202Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/fi2010/FI2010/DeepLOB.ipynb\n/kaggle/input/fi2010/FI2010/FI2010_train.csv\n/kaggle/input/fi2010/FI2010/FI2010_test.csv\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_file = '/kaggle/input/fi2010/FI2010/FI2010_train.csv'\ntest_data_file = '/kaggle/input/fi2010/FI2010/FI2010_test.csv'","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-09-12T04:24:13.724190Z","iopub.execute_input":"2021-09-12T04:24:13.724543Z","iopub.status.idle":"2021-09-12T04:24:13.730528Z","shell.execute_reply.started":"2021-09-12T04:24:13.724486Z","shell.execute_reply":"2021-09-12T04:24:13.729659Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_data_file, index_col=0)\nprint(train_data.shape)\ntest_data = pd.read_csv(test_data_file, index_col=0)\nprint(test_data.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-12T04:25:08.796981Z","iopub.execute_input":"2021-09-12T04:25:08.797304Z","iopub.status.idle":"2021-09-12T04:25:20.917504Z","shell.execute_reply.started":"2021-09-12T04:25:08.797252Z","shell.execute_reply":"2021-09-12T04:25:20.916444Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(362400, 149)\n(31937, 149)\n","output_type":"stream"}]},{"cell_type":"code","source":"# ready data for training:\n# 1. sample_size=100: the most 100 recent updates\n# 2. feature_num=40: 40 features per time stamp\n# 3. target_num=5: relative changes for the next 1,2,3,5 and 10 events(5 in total)\ndef data_generator(data, batch_size=32, lookback=100,\n                   feature_num=40, target_delay=1, shuffle=False):\n    data = data.values\n    shape = data.shape\n    max_index = shape[0]\n    min_index = 0\n    i = min_index + lookback\n    while True:\n        if shuffle:\n            rows = np.random.randint(min_index + lookack, max_index)\n        else:\n            if i + batch_size >= max_index:\n                i = min_index + lookback\n            rows = np.arange(i, min(i + batch_size, max_index))\n            i += len(rows)\n        samples = np.zeros((len(rows), lookback, feature_num))\n        targets = np.zeros((len(rows),))\n        for j, row in enumerate(rows):\n            samples[j] = data[row - lookback: row, 0: feature_num]  # take the first 40 columns as features\n            targets[j] = data[row - 1, target_delay - 6]\n        samples = samples.reshape(samples.shape[0], samples.shape[1],\n                                  samples.shape[2], 1)# add the 4th dimension: 1 channel\n        # \"Benchmark dataset for mid-price forecasting of limit order book data with machine learning\"\n        # labels 1: equal to or greater than 0.002\n        # labels 2: -0.00199 to 0.00199\n        # labels 3: smaller or equal to -0.002\n        # Y=Y-1 relabels as 0,1,2\n        targets = targets - 1\n        targets = targets.astype(int)\n        targets = to_categorical(targets, num_classes=3)# y is the next event's mid price (k=1)\n        yield samples, targets\n","metadata":{"execution":{"iopub.status.busy":"2021-09-12T01:40:21.660247Z","iopub.execute_input":"2021-09-12T01:40:21.660548Z","iopub.status.idle":"2021-09-12T01:40:21.67345Z","shell.execute_reply.started":"2021-09-12T01:40:21.660503Z","shell.execute_reply":"2021-09-12T01:40:21.672029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the size of a single input is (100,40)\ninput_tensor = Input(shape=(100,40,1))\n\n# convolutional filter is (1,2) with stride of (1,2)\nlayer_x = layers.Conv2D(16, (1,2), strides=(1,2))(input_tensor)\nlayer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\nlayer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\nlayer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\nlayer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\nlayer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n\nlayer_x = layers.Conv2D(16, (1,2), strides=(1,2))(layer_x)\nlayer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\nlayer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\nlayer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\nlayer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\nlayer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n\nlayer_x = layers.Conv2D(16, (1,10))(layer_x)\nlayer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\nlayer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\nlayer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\nlayer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\nlayer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n\n# Inception Module\ntower_1 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\ntower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\ntower_1 = layers.Conv2D(32, (3,1), padding='same')(tower_1)\ntower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\n\ntower_2 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\ntower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)\ntower_2 = layers.Conv2D(32, (5,1), padding='same')(tower_2)\ntower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)  \n\ntower_3 = layers.MaxPooling2D((3,1), padding='same', strides=(1,1))(layer_x)\ntower_3 = layers.Conv2D(32, (1,1), padding='same')(tower_3)\ntower_3 = layers.LeakyReLU(alpha=0.01)(tower_3)\n\nlayer_x = layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n\n# concatenate features of tower_1, tower_2, tower_3\nlayer_x = layers.Reshape((100,96))(layer_x)\n\n# 64 LSTM units\nlayer_x = LSTM(64)(layer_x)\n# The last output layer uses a softmax activation function\noutput = layers.Dense(3, activation='softmax')(layer_x)\nmodel = Model(input_tensor, output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T01:40:50.745847Z","iopub.execute_input":"2021-09-12T01:40:50.746167Z","iopub.status.idle":"2021-09-12T01:40:51.423724Z","shell.execute_reply.started":"2021-09-12T01:40:50.746117Z","shell.execute_reply":"2021-09-12T01:40:51.422611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nsteps_per_epoch =  len(train_data) // batch_size\ntrain_gen = data_generator(train_data, batch_size=batch_size, lookback=100,\n                   feature_num=40, target_delay=1, shuffle=False)\nopt = keras.optimizers.Adam(lr=0.01, epsilon=1)# learning rate and epsilon are the same as paper DeepLOB\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\nmodel.fit_generator(train_gen,\n                    steps_per_epoch=steps_per_epoch,\n                    epochs=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T01:41:15.869832Z","iopub.execute_input":"2021-09-12T01:41:15.870156Z","iopub.status.idle":"2021-09-12T02:52:00.625617Z","shell.execute_reply.started":"2021-09-12T01:41:15.870099Z","shell.execute_reply":"2021-09-12T02:52:00.62318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-09-12T01:40:24.92913Z","iopub.execute_input":"2021-09-12T01:40:24.929451Z","iopub.status.idle":"2021-09-12T01:40:24.934263Z","shell.execute_reply.started":"2021-09-12T01:40:24.929404Z","shell.execute_reply":"2021-09-12T01:40:24.933187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T05:10:48.297395Z","iopub.execute_input":"2021-09-12T05:10:48.297938Z","iopub.status.idle":"2021-09-12T05:10:48.330675Z","shell.execute_reply.started":"2021-09-12T05:10:48.297892Z","shell.execute_reply":"2021-09-12T05:10:48.329577Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"          0         1         2         3         4         5         6  \\\n0  0.318116 -0.564619  0.313539 -0.551889  0.319726 -0.731228  0.312891   \n1  0.318116 -0.662079  0.313539 -0.551889  0.320706 -0.751891  0.312891   \n2  0.317136 -0.723163  0.313539 -0.551889  0.316787 -0.731228  0.312891   \n3  0.317136 -0.585895  0.313539 -0.551889  0.318747 -0.307628  0.312891   \n4  0.317136 -0.585895  0.313539 -0.551889  0.318747 -0.307628  0.312891   \n\n          7         8         9  ...       139       140  141  142  143  144  \\\n0 -0.425448  0.319404 -0.844157  ... -0.816832 -0.825238  0.0  0.0  0.0  2.0   \n1 -0.425448  0.320383 -0.854876  ...  0.464300  0.452887  0.0  0.0  0.0  2.0   \n2 -0.425448  0.317445 -0.762942  ... -0.798788 -0.807237  0.0  0.0  0.0  3.0   \n3 -0.425448  0.319404 -0.561348  ...  0.465974  0.454558  0.0  0.0  0.0  2.0   \n4 -0.425448  0.319404 -0.561348  ... -0.410306 -0.419666  0.0  0.0  0.0  1.0   \n\n   145  146  147  148  \n0  2.0  2.0  2.0  2.0  \n1  2.0  2.0  2.0  2.0  \n2  3.0  2.0  2.0  2.0  \n3  2.0  3.0  2.0  2.0  \n4  1.0  1.0  2.0  2.0  \n\n[5 rows x 149 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>139</th>\n      <th>140</th>\n      <th>141</th>\n      <th>142</th>\n      <th>143</th>\n      <th>144</th>\n      <th>145</th>\n      <th>146</th>\n      <th>147</th>\n      <th>148</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.318116</td>\n      <td>-0.564619</td>\n      <td>0.313539</td>\n      <td>-0.551889</td>\n      <td>0.319726</td>\n      <td>-0.731228</td>\n      <td>0.312891</td>\n      <td>-0.425448</td>\n      <td>0.319404</td>\n      <td>-0.844157</td>\n      <td>...</td>\n      <td>-0.816832</td>\n      <td>-0.825238</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.318116</td>\n      <td>-0.662079</td>\n      <td>0.313539</td>\n      <td>-0.551889</td>\n      <td>0.320706</td>\n      <td>-0.751891</td>\n      <td>0.312891</td>\n      <td>-0.425448</td>\n      <td>0.320383</td>\n      <td>-0.854876</td>\n      <td>...</td>\n      <td>0.464300</td>\n      <td>0.452887</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.317136</td>\n      <td>-0.723163</td>\n      <td>0.313539</td>\n      <td>-0.551889</td>\n      <td>0.316787</td>\n      <td>-0.731228</td>\n      <td>0.312891</td>\n      <td>-0.425448</td>\n      <td>0.317445</td>\n      <td>-0.762942</td>\n      <td>...</td>\n      <td>-0.798788</td>\n      <td>-0.807237</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.317136</td>\n      <td>-0.585895</td>\n      <td>0.313539</td>\n      <td>-0.551889</td>\n      <td>0.318747</td>\n      <td>-0.307628</td>\n      <td>0.312891</td>\n      <td>-0.425448</td>\n      <td>0.319404</td>\n      <td>-0.561348</td>\n      <td>...</td>\n      <td>0.465974</td>\n      <td>0.454558</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.317136</td>\n      <td>-0.585895</td>\n      <td>0.313539</td>\n      <td>-0.551889</td>\n      <td>0.318747</td>\n      <td>-0.307628</td>\n      <td>0.312891</td>\n      <td>-0.425448</td>\n      <td>0.319404</td>\n      <td>-0.561348</td>\n      <td>...</td>\n      <td>-0.410306</td>\n      <td>-0.419666</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 149 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data[0:3,5:10] ## data[ row_start: row_end ,  col_start: col_end ]\ndata[4,-3]","metadata":{"execution":{"iopub.status.busy":"2021-09-12T05:11:22.886111Z","iopub.execute_input":"2021-09-12T05:11:22.886492Z","iopub.status.idle":"2021-09-12T05:11:22.892710Z","shell.execute_reply.started":"2021-09-12T05:11:22.886432Z","shell.execute_reply":"2021-09-12T05:11:22.891988Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}]},{"cell_type":"code","source":"np.unique(data[:,144] )  #  the target col ","metadata":{"execution":{"iopub.status.busy":"2021-09-12T05:24:42.677164Z","iopub.execute_input":"2021-09-12T05:24:42.677737Z","iopub.status.idle":"2021-09-12T05:24:42.698004Z","shell.execute_reply.started":"2021-09-12T05:24:42.677671Z","shell.execute_reply":"2021-09-12T05:24:42.697220Z"},"trusted":true},"execution_count":109,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"array([1., 2., 3.])"},"metadata":{}}]},{"cell_type":"code","source":"#data.shape[0]\n# np.random.randint(0 + 100, data.shape[0] )\nprint( batch_size)\nprint( max_index)\nrows = np.arange(i, min(i + batch_size, max_index))\nprint(len(rows))\nprint(f\"lookback : {lookback}\")\nprint(f\"feature_num : {feature_num}\")\nsamples = np.zeros((len(rows), lookback, feature_num))\ntargets = np.zeros((len(rows),))\n\nfor idx, row in enumerate(rows):\n    samples[idx] = data[row - 100 : row , 0:40]  ## data[ len100_row, col0_40 ]\n    print(f\"samples[idx].shape : {samples[idx].shape}\")\n    targets[idx] = data[row - 1, target_delay - 6]  # target_delay = 1\n    print(f\"targets[idx] : {targets[idx]}\")\nsamples =samples.reshape(samples.shape[0], samples.shape[1],\n                              samples.shape[2], 1)  # add 1dim   for 4th dim CNN \nsamples.shape\ntargets = targets-1\ntargets = targets.astype(int)\ntargets = to_categorical(targets, num_classes=3) # y is the next event's mid price (k=1)\ntargets  ## softMax print type\n\n# for j, row in enumerate(rows):\n#     samples[j] = data[row - lookback: row, 0: feature_num]  \n#     # take the first 40 columns as features\n#     targets[j] = data[row - 1, target_delay - 6]  ### samples's Last Row index price target\n#     samples = samples.reshape(samples.shape[0], samples.shape[1],\n#                               samples.shape[2], 1)\n#     # add the 4th dimension: 1 channel\n#         # \"Benchmark dataset for mid-price forecasting of limit order book data with machine learning\"\n#         # labels 1: equal to or greater than 0.002\n#         # labels 2: -0.00199 to 0.00199\n#         # labels 3: smaller or equal to -0.002\n#         # Y=Y-1 relabels as 0,1,2\n#     targets = targets - 1\n#     targets = targets.astype(int)\n#     targets = to_categorical(targets, num_classes=3)# y is the next event's mid price (k=1)\n#     print(f\"{samples} \\n samples.shape, {samples.shape}\")\n#     print(f\"{targets} \\n target.shape, {targets.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-12T05:20:59.348467Z","iopub.execute_input":"2021-09-12T05:20:59.348781Z","iopub.status.idle":"2021-09-12T05:20:59.373955Z","shell.execute_reply.started":"2021-09-12T05:20:59.348726Z","shell.execute_reply":"2021-09-12T05:20:59.372588Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"32\n362400\n32\nlookback : 100\nfeature_num : 40\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 1.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 1.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 1.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 2.0\nsamples[idx].shape : (100, 40)\ntargets[idx] : 3.0\n","output_type":"stream"},{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"array([[0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# ready data for training:\n# 1. sample_size=100: the most 100 recent updates\n# 2. feature_num=40: 40 features per time stamp\n# 3. target_num=5: relative changes for the next 1,2,3,5 and 10 events(5 in total)\n#def data_generator(\ndata = train_data\nbatch_size=32\nlookback=100\nfeature_num=40\ntarget_delay=1\nshuffle=False\n\ndata = data.values\nshape = data.shape\nmax_index = shape[0] #max_index = data.shape[0] = 362,400\nmin_index = 0\ni = min_index + lookback  # i = 0+ 100\n\ncounter = 0\nwhile True:\n    counter += 1\n    if counter > 2:\n        break\n    if shuffle:\n        rows = np.random.randint(min_index + lookack, max_index)  ## between range(min , max) select   randmom int\n    else:\n        if i + batch_size >= max_index:\n            i = min_index + lookback\n        rows = np.arange(i, min(i + batch_size, max_index))  ## rows index ( int array )\n        i += len(rows)\n    samples = np.zeros((len(rows), lookback, feature_num))\n    targets = np.zeros((len(rows),))\n    for j, row in enumerate(rows):\n        samples[j] = data[row - lookback: row, 0: feature_num]  # take the first 40 columns as features\n        targets[j] = data[row - 1, target_delay - 6]  ## 144 col  is target \n    samples = samples.reshape(samples.shape[0], samples.shape[1],\n                              samples.shape[2], 1)# add the 4th dimension: 1 channel\n        # \"Benchmark dataset for mid-price forecasting of limit order book data with machine learning\"\n        # labels 1: equal to or greater than 0.002\n        # labels 2: -0.00199 to 0.00199\n        # labels 3: smaller or equal to -0.002\n        # Y=Y-1 relabels as 0,1,2\n    targets = targets - 1\n    targets = targets.astype(int)\n    targets = to_categorical(targets, num_classes=3)# y is the next event's mid price (k=1)\n    print(f\"{samples} \\n samples.shape, {samples.shape}\")\n    print(f\"{targets} \\n target.shape, {targets.shape}\")\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-12T04:27:47.141093Z","iopub.execute_input":"2021-09-12T04:27:47.141396Z","iopub.status.idle":"2021-09-12T04:27:47.168909Z","shell.execute_reply.started":"2021-09-12T04:27:47.141359Z","shell.execute_reply":"2021-09-12T04:27:47.167935Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[[[[ 0.318116  ]\n   [-0.56461858]\n   [ 0.31353946]\n   ...\n   [-0.42776259]\n   [ 0.300703  ]\n   [-0.48082799]]\n\n  [[ 0.318116  ]\n   [-0.66207857]\n   [ 0.31353946]\n   ...\n   [-0.46217348]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.31713601]\n   [-0.72316264]\n   [ 0.31353946]\n   ...\n   [-0.42776259]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  ...\n\n  [[ 0.32889583]\n   [-0.58314971]\n   [ 0.32433729]\n   ...\n   [-0.46038332]\n   [ 0.32335092]\n   [-0.42121607]]\n\n  [[ 0.32889583]\n   [-0.66962828]\n   [ 0.32433729]\n   ...\n   [-0.46217348]\n   [ 0.32335092]\n   [-0.42121607]]\n\n  [[ 0.32987581]\n   [-0.53304704]\n   [ 0.32433729]\n   ...\n   [-0.44984125]\n   [ 0.32335092]\n   [-0.42121607]]]\n\n\n [[[ 0.318116  ]\n   [-0.66207857]\n   [ 0.31353946]\n   ...\n   [-0.46217348]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.31713601]\n   [-0.72316264]\n   [ 0.31353946]\n   ...\n   [-0.42776259]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.31713601]\n   [-0.58589506]\n   [ 0.31353946]\n   ...\n   [-0.46217348]\n   [ 0.300703  ]\n   [-0.48082799]]\n\n  ...\n\n  [[ 0.32889583]\n   [-0.66962828]\n   [ 0.32433729]\n   ...\n   [-0.46217348]\n   [ 0.32335092]\n   [-0.42121607]]\n\n  [[ 0.32987581]\n   [-0.53304704]\n   [ 0.32433729]\n   ...\n   [-0.44984125]\n   [ 0.32335092]\n   [-0.42121607]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32433729]\n   ...\n   [-0.44984125]\n   [ 0.32335092]\n   [-0.42121607]]]\n\n\n [[[ 0.31713601]\n   [-0.72316264]\n   [ 0.31353946]\n   ...\n   [-0.42776259]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.31713601]\n   [-0.58589506]\n   [ 0.31353946]\n   ...\n   [-0.46217348]\n   [ 0.300703  ]\n   [-0.48082799]]\n\n  [[ 0.31713601]\n   [-0.58589506]\n   [ 0.31353946]\n   ...\n   [-0.46217348]\n   [ 0.300703  ]\n   [-0.48082799]]\n\n  ...\n\n  [[ 0.32987581]\n   [-0.53304704]\n   [ 0.32433729]\n   ...\n   [-0.44984125]\n   [ 0.32335092]\n   [-0.42121607]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32433729]\n   ...\n   [-0.44984125]\n   [ 0.32335092]\n   [-0.42121607]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32433729]\n   ...\n   [-0.44984125]\n   [ 0.32335092]\n   [-0.42121607]]]\n\n\n ...\n\n\n [[[ 0.32007597]\n   [-0.66756927]\n   [ 0.3155027 ]\n   ...\n   [-0.45680299]\n   [ 0.31251931]\n   [-0.4794884 ]]\n\n  [[ 0.32007597]\n   [-0.66756927]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.32203594]\n   [-0.76365658]\n   [ 0.3155027 ]\n   ...\n   [-0.19126231]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  ...\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32728215]\n   ...\n   [-0.24277919]\n   [ 0.32630499]\n   [-0.4794884 ]]\n\n  [[ 0.32987581]\n   [-0.57559999]\n   [ 0.32728215]\n   ...\n   [-0.24277919]\n   [ 0.32433561]\n   [-0.49132147]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]]\n\n\n [[[ 0.32007597]\n   [-0.66756927]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.32203594]\n   [-0.76365658]\n   [ 0.3155027 ]\n   ...\n   [-0.19126231]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.32105595]\n   [-0.6716873 ]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  ...\n\n  [[ 0.32987581]\n   [-0.57559999]\n   [ 0.32728215]\n   ...\n   [-0.24277919]\n   [ 0.32433561]\n   [-0.49132147]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32889583]\n   [-0.63393871]\n   [ 0.32531891]\n   ...\n   [-0.24277919]\n   [ 0.32138153]\n   [-0.39777317]]]\n\n\n [[[ 0.32203594]\n   [-0.76365658]\n   [ 0.3155027 ]\n   ...\n   [-0.19126231]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.32105595]\n   [-0.6716873 ]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.32105595]\n   [-0.6716873 ]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.31251931]\n   [-0.4794884 ]]\n\n  ...\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32889583]\n   [-0.63393871]\n   [ 0.32531891]\n   ...\n   [-0.24277919]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32531891]\n   ...\n   [-0.39016919]\n   [ 0.32138153]\n   [-0.39777317]]]] \n samples.shape, (32, 100, 40, 1)\n[[1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 1. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 1. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [1. 0. 0.]] \n target.shape, (32, 3)\n[[[[ 0.32105595]\n   [-0.6716873 ]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.30956523]\n   [-0.48194432]]\n\n  [[ 0.32105595]\n   [-0.6716873 ]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.31251931]\n   [-0.4794884 ]]\n\n  [[ 0.32105595]\n   [-0.6716873 ]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.31251931]\n   [-0.4794884 ]]\n\n  ...\n\n  [[ 0.32889583]\n   [-0.63393871]\n   [ 0.32531891]\n   ...\n   [-0.24277919]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32531891]\n   ...\n   [-0.39016919]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32531891]\n   ...\n   [-0.39016919]\n   [ 0.32138153]\n   [-0.39777317]]]\n\n\n [[[ 0.32105595]\n   [-0.6716873 ]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.31251931]\n   [-0.4794884 ]]\n\n  [[ 0.32105595]\n   [-0.6716873 ]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.31251931]\n   [-0.4794884 ]]\n\n  [[ 0.32007597]\n   [-0.65041082]\n   [ 0.3155027 ]\n   ...\n   [-0.19126231]\n   [ 0.31448869]\n   [-0.47747901]]\n\n  ...\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32531891]\n   ...\n   [-0.39016919]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32531891]\n   ...\n   [-0.39016919]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32531891]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]]\n\n\n [[[ 0.32105595]\n   [-0.6716873 ]\n   [ 0.3155027 ]\n   ...\n   [-0.46217348]\n   [ 0.31251931]\n   [-0.4794884 ]]\n\n  [[ 0.32007597]\n   [-0.65041082]\n   [ 0.3155027 ]\n   ...\n   [-0.19126231]\n   [ 0.31448869]\n   [-0.47747901]]\n\n  [[ 0.32007597]\n   [-0.65041082]\n   [ 0.3155027 ]\n   ...\n   [-0.19126231]\n   [ 0.31448869]\n   [-0.47747901]]\n\n  ...\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32531891]\n   ...\n   [-0.39016919]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32987581]\n   [-0.75061616]\n   [ 0.32531891]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32987581]\n   [-0.61334858]\n   [ 0.32531891]\n   ...\n   [-0.24277919]\n   [ 0.32138153]\n   [-0.39777317]]]\n\n\n ...\n\n\n [[[ 0.32693586]\n   [-0.64835181]\n   [ 0.3204108 ]\n   ...\n   [-0.19126231]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32693586]\n   [-0.64835181]\n   [ 0.3204108 ]\n   ...\n   [-0.39016919]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32693586]\n   [-0.64835181]\n   [ 0.3204108 ]\n   ...\n   [-0.39016919]\n   [ 0.31744277]\n   [-0.47859533]]\n\n  ...\n\n  [[ 0.33183578]\n   [-0.5920721 ]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.33183578]\n   [-0.72933968]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.33183578]\n   [-0.43833241]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]]\n\n\n [[[ 0.32693586]\n   [-0.64835181]\n   [ 0.3204108 ]\n   ...\n   [-0.39016919]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.32693586]\n   [-0.64835181]\n   [ 0.3204108 ]\n   ...\n   [-0.39016919]\n   [ 0.31744277]\n   [-0.47859533]]\n\n  [[ 0.32693586]\n   [-0.51108423]\n   [ 0.3204108 ]\n   ...\n   [-0.39016919]\n   [ 0.31448869]\n   [-0.47747901]]\n\n  ...\n\n  [[ 0.33183578]\n   [-0.72933968]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.33183578]\n   [-0.43833241]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.33183578]\n   [-0.31135989]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.31842746]\n   [-0.263144  ]]]\n\n\n [[[ 0.32693586]\n   [-0.64835181]\n   [ 0.3204108 ]\n   ...\n   [-0.39016919]\n   [ 0.31744277]\n   [-0.47859533]]\n\n  [[ 0.32693586]\n   [-0.51108423]\n   [ 0.3204108 ]\n   ...\n   [-0.39016919]\n   [ 0.31448869]\n   [-0.47747901]]\n\n  [[ 0.32791584]\n   [-0.46372691]\n   [ 0.32237405]\n   ...\n   [-0.48186526]\n   [ 0.31744277]\n   [-0.47859533]]\n\n  ...\n\n  [[ 0.33183578]\n   [-0.43833241]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.32138153]\n   [-0.39777317]]\n\n  [[ 0.33183578]\n   [-0.31135989]\n   [ 0.32728215]\n   ...\n   [-0.44984125]\n   [ 0.31842746]\n   [-0.263144  ]]\n\n  [[ 0.33183578]\n   [-0.25851187]\n   [ 0.32728215]\n   ...\n   [-0.24277919]\n   [ 0.32138153]\n   [-0.39777317]]]] \n samples.shape, (32, 100, 40, 1)\n[[0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]] \n target.shape, (32, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}